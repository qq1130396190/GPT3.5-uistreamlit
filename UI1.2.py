import streamlit as st
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer
import pandas as pd
import psutil
import pyarrow.parquet as pq
from PIL import Image, ImageDraw
import os

# Define the generate_window_image function
def generate_window_image(width, height, window_color):
    image = Image.new("RGB", (width, height), "white")
    draw = ImageDraw.Draw(image)
    window_size = min(width, height) // 2
    window_x = (width - window_size) // 2
    window_y = (height - window_size) // 2
    draw.rectangle([window_x, window_y, window_x + window_size, window_y + window_size], fill=window_color)
    return image

# Function to select pretrained model and show current directory
def select_pretrained_model():
    st.subheader("é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹")

    # Show current directory
    current_directory = os.getcwd()
    st.write(f"å½“å‰æ–‡ä»¶å¤¹: {current_directory}")

    # Get all files and directories in the current directory
    files_and_dirs_in_directory = os.listdir(current_directory)

    # Separate files and directories
    files_in_directory = [f for f in files_and_dirs_in_directory if os.path.isfile(os.path.join(current_directory, f))]

    # Input for model path
    model_identifier_or_path = st.text_input("æ‰‹åŠ¨è¾“å…¥é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„:")
    if not model_identifier_or_path:
        # Input for selecting pretrained model
        selected_model = st.selectbox("é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹æˆ–æ–‡ä»¶å¤¹:", files_and_dirs_in_directory)

        # If the selected item is a file, return its path
        if os.path.isfile(os.path.join(current_directory, selected_model)):
            model_identifier_or_path = selected_model
        else:
            # If the selected item is a directory, display its contents
            model_identifier_or_path = st.selectbox("é€‰æ‹©æ–‡ä»¶:", [f for f in os.listdir(os.path.join(current_directory, selected_model))])

    return model_identifier_or_path

# Streamlit UI layout settings
st.set_page_config(page_title="Transformers UI", page_icon="ğŸ¤–", layout="wide")

# Sidebar for model selection and settings
with st.sidebar:
    st.title("Transformers UI")

    # Input for model identifier or path
    model_identifier_or_path = select_pretrained_model()

    # Input for tokenizer path
    tokenizer_identifier_or_path = st.text_input("åˆ†è¯å™¨æ ‡è¯†ç¬¦æˆ–è·¯å¾„:")

    # Input for dataset path
    dataset_path = st.text_input("æ•°æ®é›†æ–‡ä»¶è·¯å¾„:")

    debug_mode = st.checkbox("å¯ç”¨è°ƒè¯•æ¨¡å¼")

    # Upload virtual assistant image
    virtual_assistant_image = st.sidebar.file_uploader("ä¸Šä¼ è™šæ‹ŸåŠ©æ‰‹å›¾åƒæ–‡ä»¶ï¼ˆæ”¯æŒJPGã€PNGç­‰æ ¼å¼ï¼‰", type=["jpg", "png"])

# Main content area
with st.container():
    st.header("é€‰æ‹©çš„æ¨¡å‹")

    # Load selected model and tokenizer
    if model_identifier_or_path:
        try:
            model = AutoModelForCausalLM.from_pretrained(model_identifier_or_path)

            # Load tokenizer if provided, or use default
            if tokenizer_identifier_or_path:
                tokenizer = AutoTokenizer.from_pretrained(tokenizer_identifier_or_path)
            else:
                tokenizer = AutoTokenizer.from_pretrained(model_identifier_or_path)

            text_gen = pipeline("text-generation", model=model, tokenizer=tokenizer)
            st.success("æˆåŠŸåŠ è½½æŒ‡å®šè·¯å¾„æˆ–æ ‡è¯†ç¬¦çš„é¢„è®­ç»ƒæ¨¡å‹!")

            # Load dataset if provided
            if dataset_path:
                try:
                    st.write("æˆåŠŸåŠ è½½æŒ‡å®šè·¯å¾„çš„æ•°æ®é›†æ–‡ä»¶!")
                    table = pq.read_table(dataset_path)
                    df = table.to_pandas()
                    st.write("æ•°æ®é›†é¢„è§ˆ:")
                    st.write(df.head())
                except Exception as e:
                    st.error(f"åŠ è½½æ•°æ®é›†æ–‡ä»¶æ—¶å‡ºç°é”™è¯¯: {str(e)}")

            # User input for generating text
            user_input = st.text_input("æ‚¨çš„è¾“å…¥:")
            generate_button = st.button("ç”Ÿæˆ")

            # Display generated text
            if generate_button:
                if debug_mode:
                    st.write(f"è°ƒè¯•æ¨¡å¼: {debug_mode}")
                generated_text = text_gen(user_input, max_length=100)
                st.success("ç”Ÿæˆçš„æ–‡æœ¬:")
                st.write(generated_text[0]["generated_text"])

        except Exception as e:
            st.error(f"åŠ è½½æ¨¡å‹æ–‡ä»¶æ—¶å‡ºç°é”™è¯¯: {str(e)}")

    # Save chat history
    if st.button("ä¿å­˜èŠå¤©è®°å½•"):
        chat_history = st.text_area("èŠå¤©è®°å½•:", "")
        st.write("èŠå¤©è®°å½•å·²ä¿å­˜!")

    # Display 720p dialog
    st.write("720p å¯¹è¯:")
    st.text_area("", height=300)

    # Background selection
    st.sidebar.subheader("èƒŒæ™¯è®¾ç½®")
    background_color = st.sidebar.color_picker("èƒŒæ™¯é¢œè‰²", "#ffffff", key="background_color")
    st.markdown(
        f"""<style>
        .reportview-container {{
            background-color: {background_color};
        }}
        </style>""",
        unsafe_allow_html=True,
    )

    # CPU and Memory Monitor
    st.sidebar.subheader("æ€§èƒ½ç›‘æ§")
    cpu_percent = psutil.cpu_percent(interval=1) / 100.0  # å°†ç™¾åˆ†æ¯”è½¬æ¢ä¸º 0.0 åˆ° 1.0 çš„èŒƒå›´
    memory_info = psutil.virtual_memory()

    st.sidebar.text(f"CPU ä½¿ç”¨ç‡: {cpu_percent * 100}%")
    st.sidebar.progress(cpu_percent)

    st.sidebar.text(f"å†…å­˜ä½¿ç”¨ç‡: {memory_info.percent}%")
    st.sidebar.progress(memory_info.percent / 100.0)  # å°†ç™¾åˆ†æ¯”è½¬æ¢ä¸º 0.0 åˆ° 1.0 çš„èŒƒå›´

# Main content area
with st.container():
    # User input for window color
    window_color = st.color_picker("çª—æˆ·é¢œè‰²", "#87CEEB", key="window_color")  # é»˜è®¤ä¸ºå¤©è“è‰²

    # Display generated window image
    window_image = generate_window_image(400, 400, window_color)
    st.image(window_image, caption="ç”Ÿæˆçš„çª—æˆ·å›¾ç‰‡", use_column_width=True)

    # User input for image generation
    st.subheader("ç”Ÿæˆå›¾ç‰‡è¾“å…¥çª—å£")
    user_image_input = st.file_uploader("ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶ï¼ˆæ”¯æŒJPGã€PNGç­‰æ ¼å¼ï¼‰", type=["jpg", "png"])

    # Check if user has uploaded an image
    if user_image_input is not None:
        # Process the user-uploaded image
        user_image = Image.open(user_image_input)
        st.image(user_image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_column_width=True)

        # You can add your image processing logic here if needed

        # Example: Display a message
        st.write("å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼")

# Header for virtual assistant
st.header("è™šæ‹ŸäººåŠ©æ‰‹")

# Display virtual assistant image
if virtual_assistant_image is not None:
    st.image(virtual_assistant_image, caption="è™šæ‹ŸäººåŠ©æ‰‹", use_column_width=True)

# User input for interacting with the virtual assistant
user_input_va = st.text_input("æ‚¨å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ")

# Example: Virtual
